---
layout:     post
title:      "损失函数有感"
subtitle:   "误差计算 防止过拟化"
date:       2017-03-15
author:     "MrTriste"
header-img: "img/post-bg-js-module.jpg"
tags:
    - 损失函数
    - 人工智能
    - 机器学习
---

## 损失函数

损失函数的基本形式为

$$
L(w,d)=\frac{1}{N}\sum_{i=1}^N(y_i-f(x_i))^2\quad+r(d)
$$

第一项为误差 ，我们把它叫做$$R_{emp}(f)$$，第二项为模型复杂度。

为了防止模型过拟化，我们才加入模型的复杂度，在保证精确度与防止模型的过拟化，我们将两项加起来，r(d) 过大，$$R_{emp}(f)$$再小也没用；相反r(d)再小，$$R_{emp}(f)$$大也失去了问题的意义。

书本中，或者很多机器学习的资料中，为了让全球的机器学习人员有个通用的术语，同时让大家便于死记硬本，给我上一段黑体字的部分的内容加上了一坨定义，例如：我们管$$R_{emp}(f)$$叫做经验风险，管上面我们思维导图的过程叫做正则化，所以顺其自然的管r(d)叫做正则化项，然后管$$R_{emp}(f)+r(d)$$ 叫做结构风险，所以顺其自然的正则化就是我们将结构风险最小化的过程，它们是等价的。



#### 参考资料

[机器学习中常常提到的正则化到底是什么意思？](https://www.zhihu.com/question/20924039/answer/131421690)

